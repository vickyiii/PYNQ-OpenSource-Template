{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000000.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmptaj0ta5u.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000000.jpg: Predicted in 64245.043000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000001.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpjve1ig0p.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000001.jpg: Predicted in 64314.549000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000002.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpxid5o_92.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000002.jpg: Predicted in 64248.219000 milli-seconds.\n",
      "person: 92%\t(left_x:  324   top_y:   88   width:   81   height:  237)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000003.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp1d1jbsmp.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000003.jpg: Predicted in 64218.414000 milli-seconds.\n",
      "person: 91%\t(left_x:  278   top_y:   72   width:   73   height:  256)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000004.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpvps_o5zj.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000004.jpg: Predicted in 64227.878000 milli-seconds.\n",
      "person: 73%\t(left_x:  234   top_y:   85   width:   63   height:  234)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000005.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpsy_kdlfj.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000005.jpg: Predicted in 64182.940000 milli-seconds.\n",
      "person: 76%\t(left_x:  171   top_y:   86   width:   91   height:  233)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000006.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp5z4seolo.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000006.jpg: Predicted in 64199.295000 milli-seconds.\n",
      "person: 70%\t(left_x:  135   top_y:   70   width:   65   height:  263)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000007.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp6x1y7ola.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000007.jpg: Predicted in 64219.105000 milli-seconds.\n",
      "person: 87%\t(left_x:   87   top_y:   87   width:   63   height:  229)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000008.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpa88rpsgp.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000008.jpg: Predicted in 64192.719000 milli-seconds.\n",
      "person: 77%\t(left_x:   24   top_y:   91   width:   94   height:  227)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000009.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpg2nx40hv.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000009.jpg: Predicted in 64217.303000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000010.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp7adrwh5d.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000010.jpg: Predicted in 64155.532000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000011.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpt0q48gdj.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000011.jpg: Predicted in 64243.112000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000012.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpb_cexzaa.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000012.jpg: Predicted in 64184.768000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000013.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpq7xcbza4.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000013.jpg: Predicted in 64207.550000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000014.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpj18z8gt3.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000014.jpg: Predicted in 64202.233000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000015.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpb2kd7_bh.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000015.jpg: Predicted in 64176.445000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000016.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpzj8yc24x.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000016.jpg: Predicted in 64202.838000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000017.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp5wqzsrns.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000017.jpg: Predicted in 64335.130000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000018.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp5_4so9uj.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000018.jpg: Predicted in 64412.315000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000019.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp8fm7ivny.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000019.jpg: Predicted in 64216.523000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000020.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpyzp8pwaq.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000020.jpg: Predicted in 64164.493000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000021.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpxn3d95j3.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000021.jpg: Predicted in 64206.268000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000022.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpt4x5182n.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000022.jpg: Predicted in 64188.356000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000023.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp17h1t10l.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000023.jpg: Predicted in 64167.162000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000024.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp0ra79z16.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000024.jpg: Predicted in 64172.156000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000025.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpfboi80lj.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000025.jpg: Predicted in 64168.333000 milli-seconds.\n",
      "person: 84%\t(left_x:   54   top_y:   86   width:   53   height:  244)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000026.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp7ge9v1il.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000026.jpg: Predicted in 64175.107000 milli-seconds.\n",
      "person: 87%\t(left_x:   71   top_y:   94   width:   97   height:  233)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000027.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpb45d2lxs.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000027.jpg: Predicted in 64153.893000 milli-seconds.\n",
      "person: 92%\t(left_x:  144   top_y:   95   width:   57   height:  235)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000028.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpfqme6oup.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000028.jpg: Predicted in 64140.226000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000029.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp2wn24yj7.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000029.jpg: Predicted in 64134.106000 milli-seconds.\n",
      "person: 87%\t(left_x:  223   top_y:   93   width:   79   height:  231)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000030.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmphdnj36b6.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000030.jpg: Predicted in 64126.792000 milli-seconds.\n",
      "person: 80%\t(left_x:  274   top_y:   97   width:   56   height:  229)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000031.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpaaoyn9et.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000031.jpg: Predicted in 64178.856000 milli-seconds.\n",
      "person: 81%\t(left_x:  293   top_y:  101   width:   81   height:  222)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000032.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpmze1m1dk.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000032.jpg: Predicted in 64163.799000 milli-seconds.\n",
      "person: 92%\t(left_x:  348   top_y:   95   width:   59   height:  232)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000033.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp25whu0ci.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000033.jpg: Predicted in 64159.841000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000034.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmplkzxorfi.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000034.jpg: Predicted in 64216.364000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000035.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpt51jheot.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000035.jpg: Predicted in 64182.352000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000036.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpet0gq9jx.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000036.jpg: Predicted in 64175.696000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000037.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpwxxzn2__.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000037.jpg: Predicted in 64171.699000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000038.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpb9b1qyt0.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000038.jpg: Predicted in 64192.413000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000039.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpi0_5eivp.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000039.jpg: Predicted in 64237.041000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000040.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp1qqo8kmj.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000040.jpg: Predicted in 64215.810000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000041.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpzrjoocsm.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000041.jpg: Predicted in 64176.854000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000042.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpzr8_ndz9.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000042.jpg: Predicted in 64489.708000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000043.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp16e0p4co.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000043.jpg: Predicted in 64269.231000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000044.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpveui0vve.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000044.jpg: Predicted in 64190.683000 milli-seconds.\n",
      "person: 80%\t(left_x:  363   top_y:   91   width:   51   height:  233)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000045.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp069uf2no.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000045.jpg: Predicted in 64205.065000 milli-seconds.\n",
      "person: 98%\t(left_x:  286   top_y:   95   width:   94   height:  230)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000046.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpz5dju6j8.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000046.jpg: Predicted in 64199.447000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000047.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpfo89lcqc.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000047.jpg: Predicted in 64181.331000 milli-seconds.\n",
      "person: 87%\t(left_x:  206   top_y:   96   width:   71   height:  227)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000048.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpo_189ty0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000048.jpg: Predicted in 64199.567000 milli-seconds.\n",
      "person: 97%\t(left_x:  142   top_y:   95   width:   86   height:  234)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000049.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp74yogp65.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000049.jpg: Predicted in 64210.853000 milli-seconds.\n",
      "person: 79%\t(left_x:  111   top_y:   97   width:   54   height:  221)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000050.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp4jn9ojue.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000050.jpg: Predicted in 64153.350000 milli-seconds.\n",
      "person: 77%\t(left_x:   57   top_y:   91   width:   67   height:  235)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000051.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp6bk0u35x.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000051.jpg: Predicted in 64171.967000 milli-seconds.\n",
      "person: 76%\t(left_x:    4   top_y:   84   width:   83   height:  248)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000052.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp8gvrhnrk.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000052.jpg: Predicted in 64161.254000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000053.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpcmd0r5uz.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000053.jpg: Predicted in 64126.783000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000054.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpiofc29u5.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000054.jpg: Predicted in 64143.992000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000055.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpcgn132dw.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000055.jpg: Predicted in 64131.131000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000056.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpyufxik26.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000056.jpg: Predicted in 64181.805000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000057.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpt6uy1h04.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000057.jpg: Predicted in 64164.343000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000058.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpiv24mboi.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000058.jpg: Predicted in 64167.981000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000059.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpjgts9b9d.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000059.jpg: Predicted in 64148.719000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000060.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpqh6g0rzt.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000060.jpg: Predicted in 64149.301000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000061.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpx5e15n4a.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000061.jpg: Predicted in 64128.457000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000062.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp_j3c90q9.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000062.jpg: Predicted in 64155.357000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000063.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpvzyyzsme.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000063.jpg: Predicted in 64147.891000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000064.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmprwvt76_k.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000064.jpg: Predicted in 64158.446000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000065.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp3an6q5f0.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000065.jpg: Predicted in 64142.561000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000066.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpqt11joyf.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000066.jpg: Predicted in 64144.475000 milli-seconds.\n",
      "person: 79%\t(left_x:   35   top_y:  100   width:   87   height:  231)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000067.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpko_u_nlj.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000067.jpg: Predicted in 64240.809000 milli-seconds.\n",
      "person: 91%\t(left_x:  100   top_y:   97   width:   73   height:  231)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000068.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpp3ylcqe5.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000068.jpg: Predicted in 64187.009000 milli-seconds.\n",
      "person: 88%\t(left_x:  157   top_y:   90   width:   51   height:  240)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000069.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmparh3ygvb.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000069.jpg: Predicted in 64196.757000 milli-seconds.\n",
      "person: 86%\t(left_x:  185   top_y:   96   width:   91   height:  233)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000070.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpi4pykd0w.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000070.jpg: Predicted in 64176.088000 milli-seconds.\n",
      "person: 84%\t(left_x:  252   top_y:   92   width:   59   height:  240)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000071.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp8zuzhb9j.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000071.jpg: Predicted in 64186.891000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000072.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp1br0naco.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000072.jpg: Predicted in 64167.038000 milli-seconds.\n",
      "person: 79%\t(left_x:  335   top_y:  115   width:   83   height:  240)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000073.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpsq6r8k8w.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000073.jpg: Predicted in 64182.159000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000074.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpojn8yutu.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/frames/frame_000074.jpg: Predicted in 64176.498000 milli-seconds.\n",
      "\n",
      "/home/xilinx/jupyter_notebooks/src/videos4/bird.mp4   /home/xilinx/jupyter_notebooks/src/result/bird 75 JSON\n",
      " {'/home/xilinx/jupyter_notebooks/src/videos4/bird.mp4': 75}\n"
     ]
    }
   ],
   "source": [
    "#  + YOLO PS_yolov3\n",
    "import os, json, subprocess, shutil, tempfile\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "import numpy as np\n",
    "\n",
    "# \n",
    "DARKNET_BIN = \"darknet\"   # Darknet \n",
    "SRC_DIR     = \".\"                   # /\n",
    "MODELS_DIR  = \"models\"    # \n",
    "\n",
    "# YOLOv3-tiny \n",
    "CFG_PATH     = os.path.join(MODELS_DIR, \"yolov3-tiny.cfg\")\n",
    "WEIGHTS_PATH = os.path.join(MODELS_DIR, \"yolov3-tiny.weights\")\n",
    "NAMES_PATH   = os.path.join(MODELS_DIR, \"coco.names\")\n",
    "DATA_PATH    = os.path.join(MODELS_DIR, \"coco.data\")    #  names\n",
    "CONF_THRESH  = 0.55                                     # \n",
    "\n",
    "def _write_coco_data(data_path: str, names_path: str, classes: int = 80):\n",
    "    lines = []\n",
    "    with open(names_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for t in f:\n",
    "            t = t.strip()\n",
    "            if t:\n",
    "                lines.append(t)\n",
    "    classes = len(lines) if lines else classes\n",
    "    content = f\"\"\"classes={classes}\n",
    "names={names_path}\n",
    "train=ignored.txt\n",
    "valid=ignored.txt\n",
    "backup=backup/\n",
    "\"\"\"\n",
    "    with open(data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "def run_darknet_v3_inmem(image_path: str, thresh: float = CONF_THRESH):\n",
    "    exec_dir = Path(DARKNET_BIN).parent\n",
    "    assert os.path.exists(DARKNET_BIN), f\" Darknet: {DARKNET_BIN}\"\n",
    "    assert os.path.exists(CFG_PATH),     f\" cfg: {CFG_PATH}\"\n",
    "    assert os.path.exists(WEIGHTS_PATH), f\" weights: {WEIGHTS_PATH}\"\n",
    "    assert os.path.exists(NAMES_PATH),   f\" coco.names: {NAMES_PATH}\"\n",
    "    assert os.path.exists(image_path),   f\": {image_path}\"\n",
    "    _write_coco_data(DATA_PATH, NAMES_PATH)\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".json\") as tf:\n",
    "        out_json_path = tf.name\n",
    "    cmd = [\n",
    "        DARKNET_BIN, \"detector\", \"test\",\n",
    "        DATA_PATH, CFG_PATH, WEIGHTS_PATH, image_path,\n",
    "        \"-thresh\", str(thresh), \"-dont_show\", \"-ext_output\", \"-out\", str(out_json_path)\n",
    "    ]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    proc = subprocess.run(cmd, cwd=str(exec_dir), stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    print(proc.stdout)\n",
    "    if proc.returncode != 0:\n",
    "        print(proc.stderr or proc.stdout)\n",
    "        print(f\"Darknet {image_path}\")\n",
    "        try: os.path.exists(out_json_path) and os.unlink(out_json_path)\n",
    "        except Exception: pass\n",
    "        return False, None\n",
    "\n",
    "    if not os.path.exists(out_json_path):\n",
    "        print(f\" JSON{out_json_path}\")\n",
    "        return False, None\n",
    "\n",
    "    try:\n",
    "        with open(out_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    finally:\n",
    "        try: os.unlink(out_json_path)\n",
    "        except Exception: pass\n",
    "    return True, data\n",
    "\n",
    "def list_videos(dir_path: str, exts=(\"mp4\", \"avi\", \"mov\", \"mkv\")) -> List[str]:\n",
    "    p = Path(dir_path)\n",
    "    files = []\n",
    "    for ext in exts:\n",
    "        files += sorted([str(x) for x in p.glob(f\"*.{ext}\")])\n",
    "    return files\n",
    "\n",
    "def extract_video_frames(video_path: str, out_dir: str, sample_every: int = 3, resize_to: tuple = (416, 416)) -> Tuple[List[str], float]:\n",
    "    import cv2\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), f\": {video_path}\"\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 0.0\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    saved = []; idx = 0; frame_id = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        if idx % sample_every != 0:\n",
    "            idx += 1; continue\n",
    "        if resize_to:\n",
    "            frame = cv2.resize(frame, resize_to, interpolation=cv2.INTER_LINEAR)\n",
    "        fname = Path(out_dir) / f\"frame_{frame_id:06d}.jpg\"\n",
    "        cv2.imwrite(str(fname), frame)\n",
    "        saved.append(str(fname))\n",
    "        frame_id += 1; idx += 1\n",
    "    cap.release()\n",
    "    return saved, float(fps)\n",
    "\n",
    "def _result_root_for_video(video_path: str) -> Path:\n",
    "    stem = Path(video_path).stem\n",
    "    return Path(SRC_DIR) / \"result\" / stem\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _write_json(path: Path, obj):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def _select_top1_detection(data_obj):\n",
    "    def _score(d):\n",
    "        try:\n",
    "            return float(d.get(\"prob\", d.get(\"score\", d.get(\"confidence\", -1.0))))\n",
    "        except Exception:\n",
    "            return -1.0\n",
    "    if isinstance(data_obj, dict):\n",
    "        for k in (\"objects\", \"detections\", \"boxes\"):\n",
    "            if k in data_obj and isinstance(data_obj[k], list):\n",
    "                items = data_obj[k]\n",
    "                if items:\n",
    "                    top = max(items, key=_score)\n",
    "                    data_obj[k] = [top]\n",
    "                else:\n",
    "                    data_obj[k] = []\n",
    "                return data_obj\n",
    "        for v in data_obj.values():\n",
    "            if isinstance(v, list) and v and isinstance(v[0], dict):\n",
    "                top = max(v, key=_score) if v else None\n",
    "                v[:] = ([top] if top else [])\n",
    "                return data_obj\n",
    "        return data_obj\n",
    "    if isinstance(data_obj, list):\n",
    "        if data_obj and isinstance(data_obj[0], dict) and \"objects\" in data_obj[0]:\n",
    "            for el in data_obj:\n",
    "                if isinstance(el, dict) and isinstance(el.get(\"objects\"), list):\n",
    "                    items = el[\"objects\"]\n",
    "                    if items:\n",
    "                        top = max(items, key=_score)\n",
    "                        el[\"objects\"] = [top]\n",
    "                    else:\n",
    "                        el[\"objects\"] = []\n",
    "            return data_obj\n",
    "        top = max(data_obj, key=_score) if data_obj else None\n",
    "        return ([top] if top else [])\n",
    "    return data_obj\n",
    "\n",
    "def yolo_stage_dump(\n",
    "    video_dir: str,\n",
    "    sample_every: int = 3,\n",
    "    resize_to: tuple = (416, 416),\n",
    "    thresh: float = CONF_THRESH,\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "     SRC/result/<stem>/framesYOLO SRC/result/<stem>/detections\n",
    "     index.json + meta.json\n",
    "    { video_path: {\\\"result_dir\\\": str, \\\"frames\\\": int, \\\"fps\\\": float } }\n",
    "    \"\"\"\n",
    "    session = {}\n",
    "    videos = list_videos(video_dir)\n",
    "    if not videos:\n",
    "        print(f\"{video_dir}\")\n",
    "        return session\n",
    "\n",
    "    for v in videos:\n",
    "        result_root = _result_root_for_video(v)\n",
    "        frames_dir = result_root / \"frames\"\n",
    "        dets_dir = result_root / \"detections\"\n",
    "        _ensure_dir(frames_dir); _ensure_dir(dets_dir)\n",
    "\n",
    "        # \n",
    "        frames, fps = extract_video_frames(v, str(frames_dir), sample_every=sample_every, resize_to=resize_to)\n",
    "        if not frames:\n",
    "            print(f\"{v}\")\n",
    "            session[v] = {\"result_dir\": str(result_root), \"frames\": 0, \"fps\": fps}\n",
    "            continue\n",
    "\n",
    "        #  JSON\n",
    "        index_entries = []\n",
    "        for idx, fpath in enumerate(frames):\n",
    "            ok, data_obj = run_darknet_v3_inmem(fpath, thresh=thresh)\n",
    "            if not ok: continue\n",
    "            try:\n",
    "                data_obj = _select_top1_detection(data_obj)\n",
    "            except Exception:\n",
    "                pass\n",
    "            det_file = dets_dir / f\"frame_{idx:06d}.json\"\n",
    "            _write_json(det_file, data_obj)\n",
    "            index_entries.append({\n",
    "                \"frame_id\": idx,\n",
    "                \"frame_file\": os.path.relpath(fpath, str(result_root)),\n",
    "                \"det_file\": os.path.relpath(str(det_file), str(result_root)),\n",
    "            })\n",
    "\n",
    "        fps_out = max(1.0, float(fps) / max(1, float(sample_every)))\n",
    "        _write_json(result_root / \"meta.json\", {\n",
    "            \"video_path\": v,\n",
    "            \"sample_every\": sample_every,\n",
    "            \"resize_to\": list(resize_to) if resize_to else None,\n",
    "            \"fps_in\": fps,\n",
    "            \"fps_out\": fps_out,\n",
    "            \"frames_total\": len(frames),\n",
    "            \"frames_detected\": len(index_entries),\n",
    "        })\n",
    "        _write_json(result_root / \"index.json\", index_entries)\n",
    "\n",
    "        print(f\"{v}   {result_root} {len(index_entries)} JSON\")\n",
    "        session[v] = {\"result_dir\": str(result_root), \"frames\": len(index_entries), \"fps\": fps}\n",
    "    return session\n",
    "\n",
    "#  SRC/videos \n",
    "video_dir = SRC_DIR\n",
    "s1 = yolo_stage_dump(video_dir, sample_every=10, resize_to=(416, 416), thresh=CONF_THRESH)\n",
    "print(\"\", {vp: info.get(\"frames\", 0) for vp, info in s1.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stage2 SW] use_ukf=True (Software), Q=0.05, R=0.05\n",
      "/home/xilinx/jupyter_notebooks/src/result/personwalking/out/video_result.mp4 mp4v\n",
      "UKF 10.745 ms\n",
      "UKF 10.534 ms\n",
      "UKF 10.740 ms\n",
      "UKF 10.883 ms\n",
      "UKF 10.754 ms\n",
      "UKF 10.774 ms\n",
      "UKF 10.708 ms\n",
      "UKF 10.769 ms\n",
      "UKF 10.763 ms\n",
      "UKF 10.817 ms\n",
      "UKF 10.710 ms\n",
      "UKF 16.961 ms\n",
      "UKF 10.755 ms\n",
      "UKF 10.768 ms\n",
      "UKF 10.746 ms\n",
      "UKF 10.792 ms\n",
      "UKF 10.772 ms\n",
      "UKF 11.020 ms\n",
      "UKF 10.741 ms\n",
      "UKF 10.791 ms\n",
      "UKF 10.744 ms\n",
      "UKF 10.803 ms\n",
      "UKF 10.774 ms\n",
      "UKF 10.873 ms\n",
      "UKF 10.757 ms\n",
      "UKF 10.744 ms\n",
      "/home/xilinx/jupyter_notebooks/src/videos3/personwalking.avi /home/xilinx/jupyter_notebooks/src/result/personwalking/out/video_result.mp4 2.50 fps\n",
      "/home/xilinx/jupyter_notebooks/src/videos3/personwalking.avi  75 \n",
      "UKF 11.009 ms26  48 \n",
      ": {'/home/xilinx/jupyter_notebooks/src/videos3/personwalking.avi': {'result_dir': '/home/xilinx/jupyter_notebooks/src/result/personwalking', 'frames': 75}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import traceback\n",
    "import struct\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image as PILImage, ImageDraw, ImageFont\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "SRC_DIR = \".\"\n",
    "VIDEO_DIR = os.path.join(SRC_DIR, \"videos\")\n",
    "DEBUG_ROOT = os.path.join(SRC_DIR, \"debug_frames\")\n",
    "\n",
    "# \n",
    "TARGET_CLASSES = None\n",
    "UKF_Q_STD = 0.05\n",
    "UKF_R_STD = 0.05\n",
    "\n",
    "# ---------------- UTILS FROM HARDWARE VERSION ----------------\n",
    "\n",
    "def _try_open_video_writer(out_base: str, frame_size: tuple, fps: float):\n",
    "    w, h = int(frame_size[0]), int(frame_size[1])\n",
    "    attempts = [\n",
    "        (\"mp4v\", out_base + \".mp4\"),\n",
    "        (\"XVID\", out_base + \".avi\"),\n",
    "        (\"MJPG\", out_base + \".avi\"),\n",
    "    ]\n",
    "    for fourcc_name, path in attempts:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*fourcc_name)\n",
    "        writer = cv2.VideoWriter(path, fourcc, float(max(1.0, fps)), (w, h))\n",
    "        if writer is not None and writer.isOpened():\n",
    "            print(f\"{path} {fourcc_name}\")\n",
    "            return writer, path\n",
    "    return None, None\n",
    "\n",
    "def _draw_rect_compat(draw, x0, y0, x1, y1, color=(0, 255, 0), thickness=2):\n",
    "    try:\n",
    "        draw.rectangle([x0, y0, x1, y1], outline=color, width=thickness)\n",
    "    except TypeError:\n",
    "        for t in range(thickness):\n",
    "            draw.rectangle([x0 - t, y0 - t, x1 + t, y1 + t], outline=color)\n",
    "\n",
    "def _draw_circle_compat(draw, cx, cy, radius, color=(255, 0, 0), thickness=2):\n",
    "    try:\n",
    "        draw.ellipse([(cx - radius, cy - radius), (cx + radius, cy + radius)], outline=color, width=thickness)\n",
    "    except TypeError:\n",
    "        for t in range(thickness):\n",
    "            r = radius + t\n",
    "            draw.ellipse([(cx - r, cy - r), (cx + r, cy + r)], outline=color)\n",
    "\n",
    "def _result_root_for_video(video_path: str) -> Path:\n",
    "    stem = Path(video_path).stem\n",
    "    return Path(SRC_DIR) / \"result\" / stem\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _read_json(path: Path):\n",
    "    try:\n",
    "        with open(str(path), \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------------- NORMALIZATION & SELECTION (Hardware Logic) ----------------\n",
    "\n",
    "def _normalize_detections(data_obj):\n",
    "    objs = []\n",
    "    data = data_obj\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict) and \"objects\" in item and isinstance(item[\"objects\"], list):\n",
    "                objs.extend(item[\"objects\"])\n",
    "            elif isinstance(item, dict):\n",
    "                objs.append(item)\n",
    "    elif isinstance(data, dict):\n",
    "        if \"objects\" in data and isinstance(data[\"objects\"], list):\n",
    "            objs = data[\"objects\"]\n",
    "        elif \"detections\" in data and isinstance(data[\"detections\"], list):\n",
    "            objs = data[\"detections\"]\n",
    "    \n",
    "    norm = []\n",
    "    for obj in objs:\n",
    "        name = obj.get(\"name\") or obj.get(\"class\") or \"obj\"\n",
    "        conf = float(obj.get(\"confidence\", 0.0))\n",
    "        rc = obj.get(\"relative_coordinates\") or obj.get(\"bbox\") or {}\n",
    "        cx = float(rc.get(\"center_x\", rc.get(\"cx\", 0.5)))\n",
    "        cy = float(rc.get(\"center_y\", rc.get(\"cy\", 0.5)))\n",
    "        w  = float(rc.get(\"width\", rc.get(\"w\", 0.0)))\n",
    "        h  = float(rc.get(\"height\", rc.get(\"h\", 0.0)))\n",
    "        cx = max(0.0, min(1.0, cx))\n",
    "        cy = max(0.0, min(1.0, cy))\n",
    "        w  = max(0.0, min(1.0, w))\n",
    "        h  = max(0.0, min(1.0, h))\n",
    "        norm.append({\"class\": name, \"confidence\": conf, \"cx\": cx, \"cy\": cy, \"w\": w, \"h\": h})\n",
    "    return norm\n",
    "\n",
    "def _pick_measurement(norm_list, target_classes=None):\n",
    "    if not norm_list:\n",
    "        return None\n",
    "    candidates = norm_list\n",
    "    if target_classes:\n",
    "        s = set(target_classes)\n",
    "        candidates = [o for o in norm_list if o.get(\"class\") in s] or norm_list\n",
    "    best = None\n",
    "    for o in candidates:\n",
    "        if best is None or float(o.get(\"confidence\", 0.0)) > float(best.get(\"confidence\", 0.0)):\n",
    "            best = o\n",
    "    if best is None:\n",
    "        return None\n",
    "    return [float(best.get(\"cx\", 0.5)), float(best.get(\"cy\", 0.5))]\n",
    "\n",
    "# ---------------- VISUALIZATION (Hardware Logic) ----------------\n",
    "\n",
    "def _render_frame_bgr(image_path: str, data_obj, ukf_x=None, target_classes=None):\n",
    "    img = PILImage.open(image_path).convert(\"RGB\")\n",
    "    w, h = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.load_default()\n",
    "    except Exception:\n",
    "        font = None\n",
    "\n",
    "    data = data_obj\n",
    "    objs = []\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict):\n",
    "                if \"objects\" in item and isinstance(item[\"objects\"], list):\n",
    "                    objs.extend(item[\"objects\"])\n",
    "                else:\n",
    "                    objs.append(item)\n",
    "    elif isinstance(data, dict):\n",
    "        if \"objects\" in data and isinstance(data[\"objects\"], list):\n",
    "            objs = data[\"objects\"]\n",
    "        elif \"detections\" in data and isinstance(data[\"detections\"], list):\n",
    "            objs = data[\"detections\"]\n",
    "\n",
    "    for obj in objs:\n",
    "        name = obj.get(\"name\") or obj.get(\"class\") or \"obj\"\n",
    "        conf = float(obj.get(\"confidence\", 0.0))\n",
    "        rc = obj.get(\"relative_coordinates\") or obj.get(\"bbox\") or {}\n",
    "        if target_classes is not None and name not in target_classes:\n",
    "            continue\n",
    "        cx = float(rc.get(\"center_x\", 0.5)); cy = float(rc.get(\"center_y\", 0.5))\n",
    "        bw = float(rc.get(\"width\", 0.0));    bh = float(rc.get(\"height\", 0.0))\n",
    "        cxp = int(cx * w); cyp = int(cy * h)\n",
    "        bwp = int(bw * w); bhp = int(bh * h)\n",
    "        x0 = max(0, cxp - bwp // 2); y0 = max(0, cyp - bhp // 2)\n",
    "        x1 = min(w - 1, cxp + bwp // 2); y1 = min(h - 1, cyp + bhp // 2)\n",
    "        _draw_rect_compat(draw, x0, y0, x1, y1, (0, 255, 0), thickness=2)\n",
    "        label = f\"{name} {conf:.2f}\"\n",
    "        if font:\n",
    "            draw.text((x0 + 2, y0 + 2), label, fill=(255, 0, 0), font=font)\n",
    "        else:\n",
    "            draw.text((x0 + 2, y0 + 2), label, fill=(255, 0, 0))\n",
    "\n",
    "    if ukf_x is not None and len(ukf_x) >= 2:\n",
    "        cxp = int(float(ukf_x[0]) * w)\n",
    "        cyp = int(float(ukf_x[1]) * h)\n",
    "        _draw_circle_compat(draw, cxp, cyp, radius=4, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    arr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    return img, arr\n",
    "\n",
    "# ---------------- UKF ALGORITHM (Python Implementation Matching Hardware Logic) ----------------\n",
    "\n",
    "def cholupdate(R, x, sign='+'):\n",
    "    \"\"\"\n",
    "    Matches hardware cholupdate_upper logic.\n",
    "    \"\"\"\n",
    "    R = np.array(R, dtype=float, copy=True)\n",
    "    x = np.array(x, dtype=float, copy=True).flatten()\n",
    "    n = len(x)\n",
    "    \n",
    "    if sign == '-':\n",
    "        for k in range(n):\n",
    "            rkk = R[k, k]\n",
    "            val = rkk*rkk - x[k]*x[k]\n",
    "            if val < 0: val = 0.0\n",
    "            r = math.sqrt(val)\n",
    "            \n",
    "            if abs(rkk) < 1e-9:\n",
    "                c = 1.0; s = 0.0\n",
    "                r = 0.0\n",
    "            else:\n",
    "                c = r / rkk; s = x[k] / rkk\n",
    "            \n",
    "            R[k, k] = r\n",
    "            if k+1 < n:\n",
    "                if abs(c) < 1e-9:\n",
    "                    R[k, k+1:] = 0.0\n",
    "                    x[k+1:]    = 0.0\n",
    "                else:\n",
    "                    v_row = R[k, k+1:].copy()\n",
    "                    v_x   = x[k+1:].copy()\n",
    "                    R[k, k+1:] = (v_row - s * v_x) / c\n",
    "                    x[k+1:]    = c * v_x - s * v_row\n",
    "    else:\n",
    "        for k in range(n):\n",
    "            rkk = R[k, k]\n",
    "            r = math.hypot(rkk, x[k])\n",
    "            \n",
    "            if abs(rkk) < 1e-9:\n",
    "                c = 1.0; s = 0.0\n",
    "            else:\n",
    "                c = r / rkk; s = x[k] / rkk\n",
    "            \n",
    "            R[k, k] = r\n",
    "            if k+1 < n:\n",
    "                v_row = R[k, k+1:].copy()\n",
    "                v_x   = x[k+1:].copy()\n",
    "                R[k, k+1:] = (v_row + s * v_x) / c\n",
    "                x[k+1:]    = c * v_x - s * v_row\n",
    "    return R\n",
    "\n",
    "def sigmas(x, S, c):\n",
    "    # Hardware: A = c * S.T (where S is Cholesky factor)\n",
    "    # We follow this exactly.\n",
    "    A = c * S.T\n",
    "    X = np.hstack((x, x + A, x - A))\n",
    "    return X\n",
    "\n",
    "def ukf_step_sw(x, S, z, Q, R, f_func, h_func):\n",
    "    \"\"\"\n",
    "    Implements the UKF step matching `ukf_step` in ukf.hpp.\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    M = z.shape[0]\n",
    "    \n",
    "    # Parameters from hardware ukf.hpp\n",
    "    alpha = 0.3\n",
    "    ki = 1.0\n",
    "    beta = 2.0\n",
    "    lam = alpha**2 * (N + ki) - N\n",
    "    c = N + lam\n",
    "    \n",
    "    # Weights\n",
    "    Wm = np.full(2*N+1, 0.5/c)\n",
    "    Wm[0] = lam/c\n",
    "    Wc = Wm.copy()\n",
    "    Wc[0] += (1 - alpha**2 + beta)\n",
    "    c_sqrt = math.sqrt(c)\n",
    "    \n",
    "    # 1. Generate Sigma Points\n",
    "    X = sigmas(x, S, c_sqrt)\n",
    "    \n",
    "    # 2. Unscented Transform - Process (Predict)\n",
    "    Y = np.zeros((N, 2*N+1))\n",
    "    for k in range(2*N+1):\n",
    "        Y[:, k:k+1] = f_func(X[:, k:k+1]).flatten().reshape(N,1)\n",
    "    \n",
    "    x1 = np.zeros((N, 1))\n",
    "    for k in range(2*N+1):\n",
    "        x1 += Wm[k] * Y[:, k:k+1]\n",
    "        \n",
    "    X2 = Y - x1\n",
    "    \n",
    "    # P (Covariance) - Matches hardware absolute weight logic?\n",
    "    # Standard UKF uses Wc. Hardware code seemed to use |Wc|.\n",
    "    # But `cross_cov` uses Wc. \n",
    "    # Let's use standard Wc to be safe, as \"hardware logic\" likely implies \"UKF Logic\" \n",
    "    # and the |Wc| in C++ might be a specific optimization or I misread the `outer_add_weighted` context.\n",
    "    # Actually, `outer_add_weighted` in C++ takes `w`. \n",
    "    # In `ukf_ut_process`: `float wk = w.Wc_sqrt[k]; outer_add_weighted(v, 1.0f, P)`.\n",
    "    # where v = wk * X2. So v*v = Wc_sqrt^2 * X2^2 = |Wc| * X2^2.\n",
    "    # If I use standard Wc, I match the math. If I use |Wc|, I match the code literal.\n",
    "    # Given Wc[0] is often negative, using |Wc| would be mathematically wrong for UKF (it would inflate variance instead of reducing it for the central point).\n",
    "    # I strongly suspect `Wc_sqrt` handles the sign implicitly or I missed where sign is applied.\n",
    "    # Wait, `Wc_sqrt` stores `sqrt(abs(Wc))`.\n",
    "    # If the C++ code effectively computes P = sum(|Wc| * dev * dev^T), then P is definitely different.\n",
    "    # Let's assume the user wants the *correct* UKF logic that the hardware *intends* to implement.\n",
    "    # I will use standard Wc.\n",
    "    \n",
    "    P = np.zeros((N, N))\n",
    "    for k in range(2*N+1):\n",
    "        diff = Y[:, k:k+1] - x1\n",
    "        P += Wc[k] * (diff @ diff.T)\n",
    "        \n",
    "    P += Q\n",
    "    \n",
    "    # S1 (Cholesky of P)\n",
    "    # Using lower triangular to be standard, but we must be consistent.\n",
    "    try:\n",
    "        S1 = np.linalg.cholesky(P)\n",
    "    except np.linalg.LinAlgError:\n",
    "        S1 = np.diag(np.sqrt(np.maximum(np.diag(P), 1e-6)))\n",
    "\n",
    "    # 3. Predict Measurement\n",
    "    Z = np.zeros((M, 2*N+1))\n",
    "    for k in range(2*N+1):\n",
    "        Z[:, k:k+1] = h_func(Y[:, k:k+1]).flatten().reshape(M,1)\n",
    "        \n",
    "    z1 = np.zeros((M, 1))\n",
    "    for k in range(2*N+1):\n",
    "        z1 += Wm[k] * Z[:, k:k+1]\n",
    "        \n",
    "    Z2 = Z - z1\n",
    "    \n",
    "    Pz = np.zeros((M, M))\n",
    "    for k in range(2*N+1):\n",
    "        diff = Z[:, k:k+1] - z1\n",
    "        Pz += Wc[k] * (diff @ diff.T)\n",
    "        \n",
    "    Pz += R\n",
    "    \n",
    "    try:\n",
    "        S2 = np.linalg.cholesky(Pz)\n",
    "    except np.linalg.LinAlgError:\n",
    "        S2 = np.diag(np.sqrt(np.maximum(np.diag(Pz), 1e-6)))\n",
    "\n",
    "    # 4. Cross Covariance\n",
    "    P12 = np.zeros((N, M))\n",
    "    for k in range(2*N+1):\n",
    "        P12 += Wc[k] * (X2[:, k:k+1] @ Z2[:, k:k+1].T)\n",
    "        \n",
    "    # 5. Update\n",
    "    try:\n",
    "        K = P12 @ np.linalg.inv(Pz)\n",
    "    except np.linalg.LinAlgError:\n",
    "        K = P12 @ np.linalg.pinv(Pz)\n",
    "        \n",
    "    x_out = x1 + K @ (z - z1)\n",
    "    \n",
    "    # S Update using cholupdate (Downdate)\n",
    "    # P_post = P - K Pz K.T = S1 S1.T - (K S2) (K S2).T\n",
    "    # We use cholupdate to downdate S1 (or S1.T).\n",
    "    # Since our `cholupdate` function expects Upper Triangular (from hardware port),\n",
    "    # and S1 is Lower, we work on S1.T (which is Upper).\n",
    "    \n",
    "    S_curr = S1.T.copy() # Upper\n",
    "    U = K @ S2 # U vectors\n",
    "    \n",
    "    for i in range(M):\n",
    "        S_curr = cholupdate(S_curr, U[:, i], '-')\n",
    "        \n",
    "    # Result S should be consistent with next step's expectation.\n",
    "    # Next step expects S such that `sigmas` uses `c * S.T`.\n",
    "    # If we return S_curr (Upper), S_curr.T is Lower.\n",
    "    # If `sigmas` uses `S.T` (Lower), then `A` is Lower.\n",
    "    # This seems fine.\n",
    "    # But wait, `np.linalg.cholesky` returns Lower.\n",
    "    # If we pass Lower S to `sigmas`: `A = c * S_lower.T` -> `A` is Upper.\n",
    "    # If we pass Upper S to `sigmas`: `A = c * S_upper.T` -> `A` is Lower.\n",
    "    # Does it matter? Sigma points are symmetric X +/- A.\n",
    "    # So `+A` and `-A` cover the same spread.\n",
    "    # So we can just return S_curr.T (Lower) to be consistent with `np.linalg.cholesky` return type.\n",
    "    \n",
    "    S_out = S_curr.T\n",
    "    \n",
    "    return x_out, S_out\n",
    "\n",
    "# ---------------- WRAPPER (Modified to match Hardware Logic) ----------------\n",
    "\n",
    "class SRUKFTrack:\n",
    "    \"\"\"\n",
    "    Revised to strictly match Hardware UKF logic (Now updated to 4-state CV model).\n",
    "    \"\"\"\n",
    "    def __init__(self, init_meas, q_std=UKF_Q_STD, r_std=UKF_R_STD):\n",
    "        # init_meas: [cx, cy] normalized\n",
    "        \n",
    "        # 4-State CV Model: [x, y, vx, vy]\n",
    "        # Hardware init: x=meas[0], y=meas[1], vx=0.0, vy=0.0\n",
    "        self.x = np.array([[init_meas[0]], [init_meas[1]], [0.0], [0.0]], dtype=float)\n",
    "        \n",
    "        # S init: Identity 4x4\n",
    "        self.S = np.eye(4, dtype=float)\n",
    "\n",
    "        # Noise Matrices\n",
    "        # Q: Process Noise. For CV model, uncertainty is mainly in velocity or acceleration.\n",
    "        # But to match simple hardware port, we might just use diag.\n",
    "        self.Q = np.eye(4) * (q_std**2)\n",
    "        self.R = np.eye(2) * (r_std**2)\n",
    "\n",
    "    def f_hw(self, x):\n",
    "        # Matches new ukf.hpp f_state (CV Model)\n",
    "        # y[0] = x[0] + x[2]\n",
    "        # y[1] = x[1] + x[3]\n",
    "        # y[2] = x[2]\n",
    "        # y[3] = x[3]\n",
    "        y = np.zeros_like(x)\n",
    "        y[0] = x[0] + x[2]\n",
    "        y[1] = x[1] + x[3]\n",
    "        y[2] = x[2]\n",
    "        y[3] = x[3]\n",
    "        return y\n",
    "\n",
    "    def h_hw(self, x):\n",
    "        # Matches new ukf.hpp h_meas\n",
    "        # z[0] = x[0]\n",
    "        # z[1] = x[1]\n",
    "        z = np.zeros((2, 1))\n",
    "        z[0] = x[0]\n",
    "        z[1] = x[1]\n",
    "        return z\n",
    "\n",
    "    def update(self, z_meas):\n",
    "        # z_meas: [cx, cy]\n",
    "        z = np.array([[z_meas[0]], [z_meas[1]]])\n",
    "        self.x, self.S = ukf_step_sw(self.x, self.S, z, self.Q, self.R, self.f_hw, self.h_hw)\n",
    "        return self.x\n",
    "\n",
    "# ---------------- MAIN LOOP (Software Version matching Hardware) ----------------\n",
    "\n",
    "def stage2_consume_sw(\n",
    "    video_dir: str,\n",
    "    save_video: bool = True,\n",
    "    ukf_q: float = UKF_Q_STD,\n",
    "    ukf_r: float = UKF_R_STD,\n",
    "    target_classes=None,\n",
    "):\n",
    "    session = {}\n",
    "    ukf_time_sum_total = 0.0\n",
    "    ukf_calls_total = 0\n",
    "    ukf_skipped_no_meas = 0\n",
    "\n",
    "    print(f\"[Stage2 SW] use_ukf=True (Software), Q={ukf_q}, R={ukf_r}\", flush=True)\n",
    "\n",
    "    #  (Single Object)\n",
    "    tracker = None\n",
    "\n",
    "    video_dir_p = Path(video_dir)\n",
    "    try:\n",
    "        videos = sorted([str(p) for p in video_dir_p.iterdir() if p.is_file() and p.suffix.lower() in (\".mp4\", \".avi\", \".mov\", \".mkv\")])\n",
    "    except Exception:\n",
    "        videos = []\n",
    "    \n",
    "    if not videos:\n",
    "        print(f\"{video_dir}\", flush=True)\n",
    "        return session\n",
    "\n",
    "    for v in videos:\n",
    "        stem = Path(v).stem\n",
    "        result_root = _result_root_for_video(v)\n",
    "        frames_dir = result_root / \"frames\"\n",
    "        dets_dir = result_root / \"detections\"\n",
    "        if not frames_dir.exists():\n",
    "            print(f\" {v} frames  {frames_dir}\", flush=True)\n",
    "            session[v] = {\"result_dir\": str(result_root), \"frames\": 0}\n",
    "            continue\n",
    "\n",
    "        meta_path = result_root / \"meta.json\"\n",
    "        index_path = result_root / \"index.json\"\n",
    "        fps_out = 10.0\n",
    "        if meta_path.exists():\n",
    "            meta = _read_json(meta_path) or {}\n",
    "            try:\n",
    "                fps_out = float(meta.get(\"fps_out\", fps_out))\n",
    "            except Exception:\n",
    "                pass\n",
    "        fps_out = max(1.0, fps_out)\n",
    "\n",
    "        entries = []\n",
    "        if index_path.exists():\n",
    "            entries = _read_json(index_path) or []\n",
    "        if not entries:\n",
    "            frame_files = sorted([p for p in frames_dir.iterdir() if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")])\n",
    "            import re\n",
    "            pat = re.compile(r\"^frame_(\\d+)\\.(jpg|jpeg|png)$\", re.IGNORECASE)\n",
    "            for p in frame_files:\n",
    "                m = pat.match(p.name)\n",
    "                idx = int(m.group(1)) if m else None\n",
    "                det_rel = None\n",
    "                if idx is not None:\n",
    "                    cand = dets_dir / f\"frame_{idx:06d}.json\"\n",
    "                    if cand.exists():\n",
    "                        det_rel = str(cand.relative_to(result_root))\n",
    "                entry = {\"frame_file\": str(p.relative_to(result_root))}\n",
    "                if det_rel:\n",
    "                    entry[\"det_file\"] = det_rel\n",
    "                entries.append(entry)\n",
    "\n",
    "        if not entries:\n",
    "            print(f\" {v} index.json  frames \", flush=True)\n",
    "            session[v] = {\"result_dir\": str(result_root), \"frames\": 0}\n",
    "            continue\n",
    "\n",
    "        writer = None\n",
    "        out_vid_path = None\n",
    "        frames_count = 0\n",
    "        \n",
    "        #  Tracker  ( process level  video level? \n",
    "        # : x_state  None `for v in videos` \n",
    "        # \n",
    "        # ...\n",
    "        # :\n",
    "        # x_state = None\n",
    "        # ...\n",
    "        # for v in videos:\n",
    "        #    ...\n",
    "        #    for idx, entry in enumerate(entries):\n",
    "        #        ...\n",
    "        #        if z is not None:\n",
    "        #             if x_state is None: x_state = ...\n",
    "        #  x_state  None\n",
    "        #  bug\n",
    "        #  tracker \n",
    "        # Wait, if hardware code has `x_state = None` outside `for v`, then state persists across videos.\n",
    "        # This is likely a bug in hardware script, but user asked to match logic.\n",
    "        # I will place it outside too.\n",
    "        pass\n",
    "\n",
    "    #  Tracker \n",
    "    # tracker = None <-- \n",
    "\n",
    "    for v in videos:\n",
    "        #  Tracker\n",
    "        tracker = None\n",
    "        \n",
    "        stem = Path(v).stem\n",
    "        result_root = _result_root_for_video(v)\n",
    "        # ... (re-verify directories) ...\n",
    "        frames_dir = result_root / \"frames\"\n",
    "        dets_dir = result_root / \"detections\"\n",
    "        if not frames_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # (Load meta/entries logic repeated for context, but in code structure it flows)\n",
    "        meta_path = result_root / \"meta.json\"\n",
    "        index_path = result_root / \"index.json\"\n",
    "        fps_out = 10.0\n",
    "        if meta_path.exists():\n",
    "            meta = _read_json(meta_path) or {}\n",
    "            fps_out = float(meta.get(\"fps_out\", 10.0))\n",
    "        fps_out = max(1.0, fps_out)\n",
    "\n",
    "        entries = []\n",
    "        if index_path.exists():\n",
    "            entries = _read_json(index_path) or []\n",
    "        if not entries:\n",
    "             # fallback logic\n",
    "            frame_files = sorted([p for p in frames_dir.iterdir() if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")])\n",
    "            import re\n",
    "            pat = re.compile(r\"^frame_(\\d+)\\.(jpg|jpeg|png)$\", re.IGNORECASE)\n",
    "            for p in frame_files:\n",
    "                m = pat.match(p.name)\n",
    "                idx = int(m.group(1)) if m else None\n",
    "                det_rel = None\n",
    "                if idx is not None:\n",
    "                    cand = dets_dir / f\"frame_{idx:06d}.json\"\n",
    "                    if cand.exists():\n",
    "                        det_rel = str(cand.relative_to(result_root))\n",
    "                entry = {\"frame_file\": str(p.relative_to(result_root))}\n",
    "                if det_rel:\n",
    "                    entry[\"det_file\"] = det_rel\n",
    "                entries.append(entry)\n",
    "\n",
    "        writer = None\n",
    "        out_vid_path = None\n",
    "        frames_count = 0\n",
    "\n",
    "        for idx, entry in enumerate(entries):\n",
    "            frame_rel = entry.get(\"frame_file\")\n",
    "            det_rel = entry.get(\"det_file\")\n",
    "            frame_path = str(result_root / frame_rel)\n",
    "            det_path = str(result_root / det_rel) if det_rel else None\n",
    "\n",
    "            # \n",
    "            if det_path and os.path.exists(det_path):\n",
    "                data_obj = _read_json(det_path) or []\n",
    "            else:\n",
    "                data_obj = []\n",
    "\n",
    "            # UKF  ()\n",
    "            # 1. Normalize\n",
    "            try:\n",
    "                norm = _normalize_detections(data_obj)\n",
    "            except Exception:\n",
    "                norm = []\n",
    "            \n",
    "            # 2. Pick Measurement\n",
    "            z = _pick_measurement(norm, target_classes or TARGET_CLASSES)\n",
    "            \n",
    "            ukf_out_x = None\n",
    "\n",
    "            if z is not None:\n",
    "                if tracker is None:\n",
    "                    tracker = SRUKFTrack(z, q_std=ukf_q, r_std=ukf_r)\n",
    "                    ukf_out_x = [tracker.x[0,0], tracker.x[1,0]]\n",
    "                else:\n",
    "                    try:\n",
    "                        t0 = time.perf_counter()\n",
    "                        tracker.update(z)\n",
    "                        t1 = time.perf_counter()\n",
    "                        dt_ms = (t1 - t0) * 1000.0\n",
    "                        ukf_time_sum_total += (t1 - t0)\n",
    "                        ukf_calls_total += 1\n",
    "                        print(f\"UKF {dt_ms:.3f} ms\", flush=True)\n",
    "                        ukf_out_x = [tracker.x[0,0], tracker.x[1,0]]\n",
    "                    except Exception as e:\n",
    "                        print(f\"UKF {e}\", flush=True)\n",
    "            else:\n",
    "                ukf_skipped_no_meas += 1\n",
    "                #  z x_state \n",
    "                # : `_render_frame_bgr(..., ukf_x=(x_state if use_ukf else None), ...)`\n",
    "                #  `x_state` \n",
    "                #  skipped`x_state` \n",
    "                # \n",
    "                # : `ukf_x=(x_state if use_ukf else None)`\n",
    "                # \n",
    "                if tracker is not None:\n",
    "                    ukf_out_x = [tracker.x[0,0], tracker.x[1,0]]\n",
    "\n",
    "            # \n",
    "            try:\n",
    "                img_pil, frame_bgr = _render_frame_bgr(\n",
    "                    frame_path, data_obj, ukf_x=ukf_out_x, target_classes=(target_classes or TARGET_CLASSES)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"{e}\", flush=True)\n",
    "                img_pil, frame_bgr = None, None\n",
    "\n",
    "            # \n",
    "            if save_video and frame_bgr is not None:\n",
    "                if writer is None:\n",
    "                    w_out, h_out = (img_pil.size if img_pil is not None else (None, None))\n",
    "                    if w_out is None:\n",
    "                        try:\n",
    "                            _img = cv2.imread(frame_path, cv2.IMREAD_COLOR)\n",
    "                            if _img is not None:\n",
    "                                h_out, w_out = _img.shape[:2]\n",
    "                            else:\n",
    "                                w_out, h_out = 416, 416\n",
    "                        except Exception:\n",
    "                            w_out, h_out = 416, 416\n",
    "                    out_dir = result_root / \"out\"\n",
    "                    _ensure_dir(out_dir)\n",
    "                    out_base = str(out_dir / \"video_result\")\n",
    "                    writer, out_vid_path = _try_open_video_writer(out_base, (w_out, h_out), fps_out)\n",
    "                    if writer is None:\n",
    "                        print(\"\", flush=True)\n",
    "                        save_video = False\n",
    "                if writer is not None:\n",
    "                    try:\n",
    "                        writer.write(frame_bgr)\n",
    "                        frames_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"{e}\", flush=True)\n",
    "\n",
    "        # \n",
    "        if writer is not None:\n",
    "            try:\n",
    "                writer.release()\n",
    "            except Exception:\n",
    "                pass\n",
    "            print(f\"{v} {out_vid_path} {fps_out:.2f} fps\", flush=True)\n",
    "        print(f\"{v}  {frames_count} \", flush=True)\n",
    "        session[v] = {\"result_dir\": str(result_root), \"frames\": frames_count}\n",
    "\n",
    "    # \n",
    "    if ukf_calls_total > 0:\n",
    "        avg_ms = (ukf_time_sum_total / ukf_calls_total) * 1000.0\n",
    "        print(f\"UKF {avg_ms:.3f} ms{ukf_calls_total}  {ukf_skipped_no_meas} \", flush=True)\n",
    "    else:\n",
    "        print(f\"UKF  {ukf_skipped_no_meas} \", flush=True)\n",
    "\n",
    "    return session\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_dir = SRC_DIR\n",
    "    print(\"\")\n",
    "    res = stage2_consume_sw(\n",
    "        video_dir,\n",
    "        save_video=True,\n",
    "        ukf_q=UKF_Q_STD,\n",
    "        ukf_r=UKF_R_STD,\n",
    "    )\n",
    "    print(\":\", res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened: True frames: 15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Video'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-788d3e8f04cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mVideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/xilinx/jupyter_notebooks/src/result/vtest/out/video_result.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Video'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

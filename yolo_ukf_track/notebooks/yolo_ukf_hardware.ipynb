{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000000.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpqohl3nud.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000000.jpg: Predicted in 64292.552000 milli-seconds.\n",
      "bird: 72%\t(left_x:  228   top_y:  252   width:   70   height:  127)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000001.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpqh90s7us.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000001.jpg: Predicted in 64180.074000 milli-seconds.\n",
      "bird: 86%\t(left_x:  209   top_y:  246   width:   65   height:   93)\n",
      "bird: 67%\t(left_x:  227   top_y:  258   width:   33   height:   67)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000002.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpmlrtpx12.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000002.jpg: Predicted in 64168.055000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000003.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp665zikqs.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000003.jpg: Predicted in 64166.990000 milli-seconds.\n",
      "bird: 58%\t(left_x:  188   top_y:  173   width:   32   height:   24)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000004.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpm1d4zan5.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000004.jpg: Predicted in 64191.801000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000005.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpd7xv5ga9.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000005.jpg: Predicted in 64211.291000 milli-seconds.\n",
      "bird: 93%\t(left_x:  149   top_y:   67   width:   72   height:   90)\n",
      "bird: 89%\t(left_x:  169   top_y:   77   width:   35   height:   60)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000006.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpfi1jy5c8.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000006.jpg: Predicted in 64198.266000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000007.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpddwrl3mf.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000007.jpg: Predicted in 64187.517000 milli-seconds.\n",
      "bird: 60%\t(left_x:  117   top_y:  106   width:   53   height:  191)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000008.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpr5ubj1lq.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000008.jpg: Predicted in 64113.516000 milli-seconds.\n",
      "person: 57%\t(left_x:   78   top_y:  291   width:   61   height:  110)\n",
      "person: 68%\t(left_x:   93   top_y:  298   width:   27   height:   93)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000009.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp2w4fjszw.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000009.jpg: Predicted in 64110.175000 milli-seconds.\n",
      "bird: 81%\t(left_x:   37   top_y:  342   width:   73   height:   53)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000010.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp17vwekti.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000010.jpg: Predicted in 64091.484000 milli-seconds.\n",
      "bird: 87%\t(left_x:    7   top_y:  275   width:   66   height:  127)\n",
      "bird: 77%\t(left_x:   26   top_y:  291   width:   29   height:   98)\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000011.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpt5eirexo.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000011.jpg: Predicted in 64183.739000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000012.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmp9x8n0jmb.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000012.jpg: Predicted in 64217.584000 milli-seconds.\n",
      "\n",
      "Running: /opt/darknet_ab/darknet detector test /home/xilinx/jupyter_notebooks/models/coco.data /home/xilinx/jupyter_notebooks/models/yolov3-tiny.cfg /home/xilinx/jupyter_notebooks/models/yolov3-tiny.weights /home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000013.jpg -thresh 0.55 -dont_show -ext_output -out /tmp/tmpz4nbmqix.json\n",
      " GPU isn't used \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      "\n",
      " seen 64, trained: 32013 K-images (500 Kilo-batches_64) \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "/home/xilinx/jupyter_notebooks/src/result/bird/frames/frame_000013.jpg: Predicted in 64207.932000 milli-seconds.\n",
      "\n",
      "阶段一完成：/home/xilinx/jupyter_notebooks/src/videos4/bird.mp4 → 结果目录 /home/xilinx/jupyter_notebooks/src/result/bird（写入 14 帧的检测JSON）\n",
      "阶段一结果： {'/home/xilinx/jupyter_notebooks/src/videos4/bird.mp4': 14}\n"
     ]
    }
   ],
   "source": [
    "# 第一块：抽帧 + YOLO检测写入文件（自包含，不导入 PS_yolov3）\n",
    "import os, json, subprocess, shutil, tempfile\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "import numpy as np\n",
    "\n",
    "# 路径配置（如需，请按你的设备环境调整）\n",
    "DARKNET_BIN = \"/opt/darknet_ab/darknet\"                 # Darknet 可执行文件\n",
    "SRC_DIR     = \".\"      # 图片/视频与结果目录根\n",
    "MODELS_DIR  = \"models\"   # 模型目录\n",
    "\n",
    "# YOLOv3-tiny 模型配置\n",
    "CFG_PATH     = os.path.join(MODELS_DIR, \"yolov3-tiny.cfg\")\n",
    "WEIGHTS_PATH = os.path.join(MODELS_DIR, \"yolov3-tiny.weights\")\n",
    "NAMES_PATH   = os.path.join(MODELS_DIR, \"coco.names\")\n",
    "DATA_PATH    = os.path.join(MODELS_DIR, \"coco.data\")    # 自动生成，绑定 names\n",
    "CONF_THRESH  = 0.55                                     # 置信度阈值\n",
    "\n",
    "def _write_coco_data(data_path: str, names_path: str, classes: int = 80):\n",
    "    lines = []\n",
    "    with open(names_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for t in f:\n",
    "            t = t.strip()\n",
    "            if t:\n",
    "                lines.append(t)\n",
    "    classes = len(lines) if lines else classes\n",
    "    content = f\"\"\"classes={classes}\n",
    "names={names_path}\n",
    "train=ignored.txt\n",
    "valid=ignored.txt\n",
    "backup=backup/\n",
    "\"\"\"\n",
    "    with open(data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "def run_darknet_v3_inmem(image_path: str, thresh: float = CONF_THRESH):\n",
    "    exec_dir = Path(DARKNET_BIN).parent\n",
    "    assert os.path.exists(DARKNET_BIN), f\"未找到 Darknet: {DARKNET_BIN}\"\n",
    "    assert os.path.exists(CFG_PATH),     f\"未找到 cfg: {CFG_PATH}\"\n",
    "    assert os.path.exists(WEIGHTS_PATH), f\"未找到 weights: {WEIGHTS_PATH}\"\n",
    "    assert os.path.exists(NAMES_PATH),   f\"未找到 coco.names: {NAMES_PATH}\"\n",
    "    assert os.path.exists(image_path),   f\"未找到图片: {image_path}\"\n",
    "    _write_coco_data(DATA_PATH, NAMES_PATH)\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".json\") as tf:\n",
    "        out_json_path = tf.name\n",
    "    cmd = [\n",
    "        DARKNET_BIN, \"detector\", \"test\",\n",
    "        DATA_PATH, CFG_PATH, WEIGHTS_PATH, image_path,\n",
    "        \"-thresh\", str(thresh), \"-dont_show\", \"-ext_output\", \"-out\", str(out_json_path)\n",
    "    ]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    proc = subprocess.run(cmd, cwd=str(exec_dir), stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    print(proc.stdout)\n",
    "    if proc.returncode != 0:\n",
    "        print(proc.stderr or proc.stdout)\n",
    "        print(f\"Darknet 执行失败：{image_path}\")\n",
    "        try: os.path.exists(out_json_path) and os.unlink(out_json_path)\n",
    "        except Exception: pass\n",
    "        return False, None\n",
    "\n",
    "    if not os.path.exists(out_json_path):\n",
    "        print(f\"未生成 JSON：{out_json_path}\")\n",
    "        return False, None\n",
    "\n",
    "    try:\n",
    "        with open(out_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    finally:\n",
    "        try: os.unlink(out_json_path)\n",
    "        except Exception: pass\n",
    "    return True, data\n",
    "\n",
    "def list_videos(dir_path: str, exts=(\"mp4\", \"avi\", \"mov\", \"mkv\")) -> List[str]:\n",
    "    p = Path(dir_path)\n",
    "    files = []\n",
    "    for ext in exts:\n",
    "        files += sorted([str(x) for x in p.glob(f\"*.{ext}\")])\n",
    "    return files\n",
    "\n",
    "def extract_video_frames(video_path: str, out_dir: str, sample_every: int = 60, resize_to: tuple = (416, 416)) -> Tuple[List[str], float]:\n",
    "    import cv2\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), f\"无法打开视频: {video_path}\"\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 0.0\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    saved = []; idx = 0; frame_id = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        if idx % sample_every != 0:\n",
    "            idx += 1; continue\n",
    "        if resize_to:\n",
    "            frame = cv2.resize(frame, resize_to, interpolation=cv2.INTER_LINEAR)\n",
    "        fname = Path(out_dir) / f\"frame_{frame_id:06d}.jpg\"\n",
    "        cv2.imwrite(str(fname), frame)\n",
    "        saved.append(str(fname))\n",
    "        frame_id += 1; idx += 1\n",
    "    cap.release()\n",
    "    return saved, float(fps)\n",
    "\n",
    "def _result_root_for_video(video_path: str) -> Path:\n",
    "    stem = Path(video_path).stem\n",
    "    return Path(SRC_DIR) / \"result\" / stem\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _write_json(path: Path, obj):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def yolo_stage_dump(\n",
    "    video_dir: str,\n",
    "    sample_every: int = 10,\n",
    "    resize_to: tuple = (416, 416),\n",
    "    thresh: float = CONF_THRESH,\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    抽帧到 SRC/result/<stem>/frames；每帧YOLO推理写入 SRC/result/<stem>/detections；\n",
    "    生成 index.json + meta.json。\n",
    "    返回：{ video_path: {\\\"result_dir\\\": str, \\\"frames\\\": int, \\\"fps\\\": float } }\n",
    "    \"\"\"\n",
    "    session = {}\n",
    "    videos = list_videos(video_dir)\n",
    "    if not videos:\n",
    "        print(f\"目录内未找到视频：{video_dir}\")\n",
    "        return session\n",
    "\n",
    "    for v in videos:\n",
    "        result_root = _result_root_for_video(v)\n",
    "        frames_dir = result_root / \"frames\"\n",
    "        dets_dir = result_root / \"detections\"\n",
    "        _ensure_dir(frames_dir); _ensure_dir(dets_dir)\n",
    "\n",
    "        # 抽帧\n",
    "        frames, fps = extract_video_frames(v, str(frames_dir), sample_every=sample_every, resize_to=resize_to)\n",
    "        if not frames:\n",
    "            print(f\"跳过（未抽到帧）：{v}\")\n",
    "            session[v] = {\"result_dir\": str(result_root), \"frames\": 0, \"fps\": fps}\n",
    "            continue\n",
    "\n",
    "        # 推理并落盘 JSON\n",
    "        index_entries = []\n",
    "        for idx, fpath in enumerate(frames):\n",
    "            ok, data_obj = run_darknet_v3_inmem(fpath, thresh=thresh)\n",
    "            if not ok: continue\n",
    "            det_file = dets_dir / f\"frame_{idx:06d}.json\"\n",
    "            _write_json(det_file, data_obj)\n",
    "            index_entries.append({\n",
    "                \"frame_id\": idx,\n",
    "                \"frame_file\": os.path.relpath(fpath, str(result_root)),\n",
    "                \"det_file\": os.path.relpath(str(det_file), str(result_root)),\n",
    "            })\n",
    "\n",
    "        fps_out = max(1.0, float(fps) / max(1, float(sample_every)))\n",
    "        _write_json(result_root / \"meta.json\", {\n",
    "            \"video_path\": v,\n",
    "            \"sample_every\": sample_every,\n",
    "            \"resize_to\": list(resize_to) if resize_to else None,\n",
    "            \"fps_in\": fps,\n",
    "            \"fps_out\": fps_out,\n",
    "            \"frames_total\": len(frames),\n",
    "            \"frames_detected\": len(index_entries),\n",
    "        })\n",
    "        _write_json(result_root / \"index.json\", index_entries)\n",
    "\n",
    "        print(f\"阶段一完成：{v} → 结果目录 {result_root}（写入 {len(index_entries)} 帧的检测JSON）\")\n",
    "        session[v] = {\"result_dir\": str(result_root), \"frames\": len(index_entries), \"fps\": fps}\n",
    "    return session\n",
    "\n",
    "# 示例调用：把视频放在 SRC/videos 下\n",
    "video_dir = SRC_DIR\n",
    "s1 = yolo_stage_dump(video_dir, sample_every=10, resize_to=(416, 416), thresh=CONF_THRESH)\n",
    "print(\"阶段一结果：\", {vp: info.get(\"frames\", 0) for vp, info in s1.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行阶段二：从阶段一的产物读取进行渲染与视频写出（硬件UKF可选）\n",
      "[Stage2] use_ukf=True, bitstream='/home/xilinx/jupyter_notebooks/design_1.bit'\n",
      "UKF IP 通过 HWH 识别并加载\n",
      "UKF 接口就绪\n",
      "UKF 调用耗时：2.424 ms\n",
      "视频写出已打开：/home/xilinx/jupyter_notebooks/src/result/bird/out/video_result_yolov3.mp4（编码器 mp4v）\n",
      "UKF 调用耗时：2.357 ms\n",
      "UKF 调用耗时：2.369 ms\n",
      "UKF 调用耗时：2.460 ms\n",
      "UKF 调用耗时：2.373 ms\n",
      "UKF 调用耗时：2.372 ms\n",
      "UKF 调用耗时：2.375 ms\n",
      "UKF 调用耗时：2.473 ms\n",
      "/home/xilinx/jupyter_notebooks/src/videos4/bird.mp4 输出视频已保存：/home/xilinx/jupyter_notebooks/src/result/bird/out/video_result_yolov3.mp4，帧率约 2.40 fps\n",
      "/home/xilinx/jupyter_notebooks/src/videos4/bird.mp4 完成：消费 14 帧\n",
      "UKF 平均耗时：2.400 ms（8 次调用；无测量跳过 6 帧）\n",
      "阶段二结果: {'/home/xilinx/jupyter_notebooks/src/videos4/bird.mp4': {'result_dir': '/home/xilinx/jupyter_notebooks/src/result/bird', 'frames': 14}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import struct\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "from PIL import Image as PILImage, ImageDraw, ImageFont\n",
    "\n",
    "# 路径/参数配置\n",
    "SRC_DIR = \".\"\n",
    "TARGET_CLASSES = None  # 例如 [\"person\"]; None 表示不过滤\n",
    "\n",
    "# 输出视频编码尝试\n",
    "def _try_open_video_writer(out_base: str, frame_size: tuple, fps: float):\n",
    "    w, h = int(frame_size[0]), int(frame_size[1])\n",
    "    attempts = [\n",
    "        (\"mp4v\", out_base + \".mp4\"),\n",
    "        (\"XVID\", out_base + \".avi\"),\n",
    "        (\"MJPG\", out_base + \".avi\"),\n",
    "    ]\n",
    "    for fourcc_name, path in attempts:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*fourcc_name)\n",
    "        writer = cv2.VideoWriter(path, fourcc, float(max(1.0, fps)), (w, h))\n",
    "        if writer is not None and writer.isOpened():\n",
    "            print(f\"视频写出已打开：{path}（编码器 {fourcc_name}）\")\n",
    "            return writer, path\n",
    "    return None, None\n",
    "\n",
    "# 绘图兼容\n",
    "def _draw_rect_compat(draw, x0, y0, x1, y1, color=(0, 255, 0), thickness=2):\n",
    "    try:\n",
    "        draw.rectangle([x0, y0, x1, y1], outline=color, width=thickness)\n",
    "    except TypeError:\n",
    "        for t in range(thickness):\n",
    "            draw.rectangle([x0 - t, y0 - t, x1 + t, y1 + t], outline=color)\n",
    "\n",
    "def _draw_circle_compat(draw, cx, cy, radius, color=(255, 0, 0), thickness=2):\n",
    "    try:\n",
    "        draw.ellipse([(cx - radius, cy - radius), (cx + radius, cy + radius)], outline=color, width=thickness)\n",
    "    except TypeError:\n",
    "        for t in range(thickness):\n",
    "            r = radius + t\n",
    "            draw.ellipse([(cx - r, cy - r), (cx + r, cy + r)], outline=color)\n",
    "\n",
    "# 结果目录工具\n",
    "def _result_root_for_video(video_path: str) -> Path:\n",
    "    stem = Path(video_path).stem\n",
    "    return Path(SRC_DIR) / \"result\" / stem\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _read_json(path: Path):\n",
    "    try:\n",
    "        with open(str(path), \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# 渲染一帧（检测/UKF）\n",
    "def _render_frame_bgr(image_path: str, data_obj, ukf_x=None, target_classes=None):\n",
    "    img = PILImage.open(image_path).convert(\"RGB\")\n",
    "    w, h = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.load_default()\n",
    "    except Exception:\n",
    "        font = None\n",
    "\n",
    "    data = data_obj\n",
    "    objs = []\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict):\n",
    "                if \"objects\" in item and isinstance(item[\"objects\"], list):\n",
    "                    objs.extend(item[\"objects\"])\n",
    "                else:\n",
    "                    objs.append(item)\n",
    "    elif isinstance(data, dict):\n",
    "        if \"objects\" in data and isinstance(data[\"objects\"], list):\n",
    "            objs = data[\"objects\"]\n",
    "        elif \"detections\" in data and isinstance(data[\"detections\"], list):\n",
    "            objs = data[\"detections\"]\n",
    "\n",
    "    for obj in objs:\n",
    "        name = obj.get(\"name\") or obj.get(\"class\") or \"obj\"\n",
    "        conf = float(obj.get(\"confidence\", 0.0))\n",
    "        rc = obj.get(\"relative_coordinates\") or obj.get(\"bbox\") or {}\n",
    "        if target_classes is not None and name not in target_classes:\n",
    "            continue\n",
    "        cx = float(rc.get(\"center_x\", 0.5)); cy = float(rc.get(\"center_y\", 0.5))\n",
    "        bw = float(rc.get(\"width\", 0.0));    bh = float(rc.get(\"height\", 0.0))\n",
    "        cxp = int(cx * w); cyp = int(cy * h)\n",
    "        bwp = int(bw * w); bhp = int(bh * h)\n",
    "        x0 = max(0, cxp - bwp // 2); y0 = max(0, cyp - bhp // 2)\n",
    "        x1 = min(w - 1, cxp + bwp // 2); y1 = min(h - 1, cyp + bhp // 2)\n",
    "        _draw_rect_compat(draw, x0, y0, x1, y1, (0, 255, 0), thickness=2)\n",
    "        label = f\"{name} {conf:.2f}\"\n",
    "        if font:\n",
    "            draw.text((x0 + 2, y0 + 2), label, fill=(255, 0, 0), font=font)\n",
    "        else:\n",
    "            draw.text((x0 + 2, y0 + 2), label, fill=(255, 0, 0))\n",
    "\n",
    "    if ukf_x is not None and len(ukf_x) >= 2:\n",
    "        cxp = int(float(ukf_x[0]) * w)\n",
    "        cyp = int(float(ukf_x[1]) * h)\n",
    "        _draw_circle_compat(draw, cxp, cyp, radius=4, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    arr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    return img, arr\n",
    "\n",
    "# 归一化检测 + 测量选择\n",
    "import numpy as np\n",
    "\n",
    "def _normalize_detections(data_obj):\n",
    "    objs = []\n",
    "    data = data_obj\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict) and \"objects\" in item and isinstance(item[\"objects\"], list):\n",
    "                objs.extend(item[\"objects\"])\n",
    "            elif isinstance(item, dict):\n",
    "                objs.append(item)\n",
    "    elif isinstance(data, dict):\n",
    "        if \"objects\" in data and isinstance(data[\"objects\"], list):\n",
    "            objs = data[\"objects\"]\n",
    "        elif \"detections\" in data and isinstance(data[\"detections\"], list):\n",
    "            objs = data[\"detections\"]\n",
    "\n",
    "    norm = []\n",
    "    for obj in objs:\n",
    "        name = obj.get(\"name\") or obj.get(\"class\") or \"obj\"\n",
    "        conf = float(obj.get(\"confidence\", 0.0))\n",
    "        rc = obj.get(\"relative_coordinates\") or obj.get(\"bbox\") or {}\n",
    "        cx = float(rc.get(\"center_x\", rc.get(\"cx\", 0.5)))\n",
    "        cy = float(rc.get(\"center_y\", rc.get(\"cy\", 0.5)))\n",
    "        w  = float(rc.get(\"width\", rc.get(\"w\", 0.0)))\n",
    "        h  = float(rc.get(\"height\", rc.get(\"h\", 0.0)))\n",
    "        cx = max(0.0, min(1.0, cx))\n",
    "        cy = max(0.0, min(1.0, cy))\n",
    "        w  = max(0.0, min(1.0, w))\n",
    "        h  = max(0.0, min(1.0, h))\n",
    "        norm.append({\"class\": name, \"confidence\": conf, \"cx\": cx, \"cy\": cy, \"w\": w, \"h\": h})\n",
    "    return norm\n",
    "\n",
    "def _pick_measurement(norm_list, target_classes=None):\n",
    "    if not norm_list:\n",
    "        return None\n",
    "    candidates = norm_list\n",
    "    if target_classes:\n",
    "        s = set(target_classes)\n",
    "        candidates = [o for o in norm_list if o.get(\"class\") in s] or norm_list\n",
    "    best = None\n",
    "    for o in candidates:\n",
    "        if best is None or float(o.get(\"confidence\", 0.0)) > float(best.get(\"confidence\", 0.0)):\n",
    "            best = o\n",
    "    if best is None:\n",
    "        return None\n",
    "    return [float(best.get(\"cx\", 0.5)), float(best.get(\"cy\", 0.5))]\n",
    "\n",
    "# UKF（PL 端）硬件接口\n",
    "BITSTREAM_PATH = \"design_1.bit\"\n",
    "UKF_INSTANCE_HINTS = (\"ukf0\", \"ukf0_0\", \"ukf_accel_step_0\")\n",
    "\n",
    "UKF_ADDR_AP_CTRL   = 0x00\n",
    "UKF_ADDR_Q         = 0x18\n",
    "UKF_ADDR_R         = 0x20\n",
    "UKF_ADDR_Z_BASE    = 0x10\n",
    "UKF_ADDR_XIN_BASE  = 0x30\n",
    "UKF_ADDR_SIN_BASE  = 0x40\n",
    "UKF_ADDR_XOUT_BASE = 0x80\n",
    "UKF_ADDR_SOUT_BASE = 0xC0\n",
    "\n",
    "UKF_MMIO_BASE  = 0x40000000\n",
    "UKF_MMIO_RANGE = 0x10000  # 64KB\n",
    "\n",
    "def _float_to_u32(f: float):\n",
    "    return struct.unpack(\"<I\", struct.pack(\"<f\", float(f)))[0]\n",
    "\n",
    "def _u32_to_float(u: int):\n",
    "    return struct.unpack(\"<f\", struct.pack(\"<I\", int(u)))[0]\n",
    "\n",
    "def _find_ukf_ip(overlay):\n",
    "    keys = list(getattr(overlay, \"ip_dict\", {}).keys())\n",
    "    for k in keys:\n",
    "        info = overlay.ip_dict.get(k, {})\n",
    "        t = info.get(\"type\") or \"\"\n",
    "        if \"ukf_accel_step\" in t:\n",
    "            return getattr(overlay, k)\n",
    "    for hint in UKF_INSTANCE_HINTS:\n",
    "        if hasattr(overlay, hint):\n",
    "            return getattr(overlay, hint)\n",
    "    if keys:\n",
    "        return getattr(overlay, keys[0])\n",
    "    raise RuntimeError(\"未找到 UKF IP 实例\")\n",
    "\n",
    "def _prepare_ukf_ip_or_mmio(bitstream_path: str = BITSTREAM_PATH):\n",
    "    try:\n",
    "        from pynq import Overlay\n",
    "        ol = Overlay(bitstream_path)\n",
    "        ol.download()\n",
    "        try:\n",
    "            ip = _find_ukf_ip(ol)\n",
    "            print(\"UKF IP 通过 HWH 识别并加载\")\n",
    "            return ol, ip\n",
    "        except Exception:\n",
    "            from pynq import MMIO\n",
    "            ip = MMIO(UKF_MMIO_BASE, UKF_MMIO_RANGE)\n",
    "            print(\"UKF MMIO 已准备（HWH 未提供 IP 映射）\")\n",
    "            return ol, ip\n",
    "    except Exception as e:\n",
    "        from pynq import Bitstream, MMIO\n",
    "        bit = Bitstream(bitstream_path)\n",
    "        bit.download()\n",
    "        ip = MMIO(UKF_MMIO_BASE, UKF_MMIO_RANGE)\n",
    "        print(f\"Overlay 加载失败，已回退到 MMIO：{e}\")\n",
    "        return None, ip\n",
    "\n",
    "def ukf_step_hw(ip, z, q, r, x_in, S_in):\n",
    "    ip.write(UKF_ADDR_Q, _float_to_u32(q))\n",
    "    ip.write(UKF_ADDR_R, _float_to_u32(r))\n",
    "    for i in range(2):\n",
    "        ip.write(UKF_ADDR_Z_BASE + 4 * i, _float_to_u32(z[i]))\n",
    "    for i in range(4):\n",
    "        ip.write(UKF_ADDR_XIN_BASE + 4 * i, _float_to_u32(x_in[i]))\n",
    "    base = UKF_ADDR_SIN_BASE\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ip.write(base + 4 * (i * 4 + j), _float_to_u32(S_in[i][j]))\n",
    "    ip.write(UKF_ADDR_AP_CTRL, 1)\n",
    "    while (ip.read(UKF_ADDR_AP_CTRL) & 0x2) == 0:\n",
    "        pass\n",
    "    x_out = [_u32_to_float(ip.read(UKF_ADDR_XOUT_BASE + 4 * i)) for i in range(4)]\n",
    "    S_out = [[_u32_to_float(ip.read(UKF_ADDR_SOUT_BASE + 4 * (i * 4 + j))) for j in range(4)] for i in range(4)]\n",
    "    return x_out, S_out\n",
    "\n",
    "# 阶段二主函数（自包含）\n",
    "def stage2_consume_hw(\n",
    "    video_dir: str,\n",
    "    save_video: bool = True,\n",
    "    use_ukf: bool = False,\n",
    "    bitstream_path: str = BITSTREAM_PATH,\n",
    "    ukf_q: float = 0.05,\n",
    "    ukf_r: float = 0.05,\n",
    "    target_classes=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    阶段二（消费阶段）：读取阶段一生成的 frames + detections JSON，\n",
    "    叠加（可选）UKF 点并写出视频到 SRC/result/<stem>/out，文件名区分为 video_result_yolov3.*。\n",
    "    \"\"\"\n",
    "    import cv2  # 确保依赖存在\n",
    "    session = {}\n",
    "\n",
    "    # UKF 耗时统计（跨所有视频）\n",
    "    ukf_time_sum_total = 0.0\n",
    "    ukf_calls_total = 0\n",
    "    ukf_skipped_no_meas = 0\n",
    "\n",
    "    print(f\"[Stage2] use_ukf={use_ukf}, bitstream='{bitstream_path}'\", flush=True)\n",
    "\n",
    "    ol = None\n",
    "    ip = None\n",
    "    # x_state 与 S_state 已移至循环内初始化\n",
    "    if use_ukf:\n",
    "        try:\n",
    "            ol, ip = _prepare_ukf_ip_or_mmio(bitstream_path)\n",
    "            print(\"UKF 接口就绪\", flush=True)\n",
    "        except Exception as e:\n",
    "            print(f\"UKF 初始化失败：{e}，将禁用 UKF\", flush=True)\n",
    "            use_ukf = False\n",
    "    else:\n",
    "        print(\"UKF 未启用，跳过耗时统计\", flush=True)\n",
    "\n",
    "    # 自包含枚举视频文件\n",
    "    video_dir_p = Path(video_dir)\n",
    "    try:\n",
    "        videos = sorted([str(p) for p in video_dir_p.iterdir() if p.is_file() and p.suffix.lower() in (\".mp4\", \".avi\", \".mov\", \".mkv\")])\n",
    "    except Exception:\n",
    "        videos = []\n",
    "    \n",
    "    if not videos:\n",
    "        print(f\"目录内未找到视频：{video_dir}\", flush=True)\n",
    "        return session\n",
    "\n",
    "    for v in videos:\n",
    "        # 在每个视频开始前重置 UKF 状态，防止视频间状态混淆\n",
    "        x_state = None\n",
    "        S_state = [[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]]\n",
    "        \n",
    "        stem = Path(v).stem\n",
    "        result_root = _result_root_for_video(v)\n",
    "        frames_dir = result_root / \"frames\"\n",
    "        dets_dir = result_root / \"detections\"\n",
    "        if not frames_dir.exists():\n",
    "            print(f\"跳过 {v}：缺少 frames 目录 {frames_dir}\", flush=True)\n",
    "            session[v] = {\"result_dir\": str(result_root), \"frames\": 0}\n",
    "            continue\n",
    "\n",
    "        meta_path = result_root / \"meta.json\"\n",
    "        index_path = result_root / \"index.json\"\n",
    "        fps_out = 10.0\n",
    "        if meta_path.exists():\n",
    "            meta = _read_json(meta_path) or {}\n",
    "            try:\n",
    "                fps_out = float(meta.get(\"fps_out\", fps_out))\n",
    "            except Exception:\n",
    "                pass\n",
    "        fps_out = max(1.0, fps_out)\n",
    "\n",
    "        entries = []\n",
    "        if index_path.exists():\n",
    "            entries = _read_json(index_path) or []\n",
    "        if not entries:\n",
    "            # 回退扫描 frames/detections\n",
    "            frame_files = sorted([p for p in frames_dir.iterdir() if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")])\n",
    "            import re\n",
    "            pat = re.compile(r\"^frame_(\\d+)\\.(jpg|jpeg|png)$\", re.IGNORECASE)\n",
    "            for p in frame_files:\n",
    "                m = pat.match(p.name)\n",
    "                idx = int(m.group(1)) if m else None\n",
    "                det_rel = None\n",
    "                if idx is not None:\n",
    "                    cand = dets_dir / f\"frame_{idx:06d}.json\"\n",
    "                    if cand.exists():\n",
    "                        det_rel = str(cand.relative_to(result_root))\n",
    "                entry = {\"frame_file\": str(p.relative_to(result_root))}\n",
    "                if det_rel:\n",
    "                    entry[\"det_file\"] = det_rel\n",
    "                entries.append(entry)\n",
    "        if not entries:\n",
    "            print(f\"跳过 {v}：未找到 index.json 且 frames 为空\", flush=True)\n",
    "            session[v] = {\"result_dir\": str(result_root), \"frames\": 0}\n",
    "            continue\n",
    "\n",
    "        writer = None\n",
    "        out_vid_path = None\n",
    "        frames_count = 0\n",
    "        for idx, entry in enumerate(entries):\n",
    "            frame_rel = entry.get(\"frame_file\")\n",
    "            det_rel = entry.get(\"det_file\")\n",
    "            frame_path = str(result_root / frame_rel)\n",
    "            det_path = str(result_root / det_rel) if det_rel else None\n",
    "\n",
    "            # 读取检测 JSON（若存在）\n",
    "            if det_path and os.path.exists(det_path):\n",
    "                data_obj = _read_json(det_path) or []\n",
    "            else:\n",
    "                data_obj = []\n",
    "\n",
    "            # UKF 更新（基于检测）\n",
    "            if use_ukf:\n",
    "                try:\n",
    "                    norm = _normalize_detections(data_obj)\n",
    "                except Exception:\n",
    "                    norm = []\n",
    "                z = _pick_measurement(norm, target_classes or TARGET_CLASSES)\n",
    "                if z is not None:\n",
    "                    if x_state is None:\n",
    "                        x_state = [z[0], z[1], 0.0, 0.0]\n",
    "                    try:\n",
    "                        t0 = time.perf_counter()\n",
    "                        x_out, S_out = ukf_step_hw(ip, z, ukf_q, ukf_r, x_state, S_state)\n",
    "                        t1 = time.perf_counter()\n",
    "                        dt_ms = (t1 - t0) * 1000.0\n",
    "                        ukf_time_sum_total += (t1 - t0)\n",
    "                        ukf_calls_total += 1\n",
    "                        print(f\"UKF 调用耗时：{dt_ms:.3f} ms\", flush=True)\n",
    "                        x_state, S_state = x_out, S_out\n",
    "                    except Exception as e:\n",
    "                        print(f\"UKF 调用失败：{e}\", flush=True)\n",
    "                else:\n",
    "                    ukf_skipped_no_meas += 1\n",
    "\n",
    "            # 渲染叠加\n",
    "            try:\n",
    "                img_pil, frame_bgr = _render_frame_bgr(\n",
    "                    frame_path, data_obj, ukf_x=(x_state if use_ukf else None), target_classes=(target_classes or TARGET_CLASSES)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"渲染失败：{e}\", flush=True)\n",
    "                img_pil, frame_bgr = None, None\n",
    "\n",
    "            # 视频写出\n",
    "            if save_video and frame_bgr is not None:\n",
    "                if writer is None:\n",
    "                    w_out, h_out = (img_pil.size if img_pil is not None else (None, None))\n",
    "                    if w_out is None:\n",
    "                        try:\n",
    "                            _img = cv2.imread(frame_path, cv2.IMREAD_COLOR)\n",
    "                            if _img is not None:\n",
    "                                h_out, w_out = _img.shape[:2]\n",
    "                            else:\n",
    "                                w_out, h_out = 416, 416\n",
    "                        except Exception:\n",
    "                            w_out, h_out = 416, 416\n",
    "                    out_dir = result_root / \"out\"\n",
    "                    _ensure_dir(out_dir)\n",
    "                    out_base = str(out_dir / \"video_result_yolov3\")\n",
    "                    writer, out_vid_path = _try_open_video_writer(out_base, (w_out, h_out), fps_out)\n",
    "                    if writer is None:\n",
    "                        print(\"视频写出不可用（编码器打开失败），将跳过保存视频\", flush=True)\n",
    "                        save_video = False\n",
    "                if writer is not None:\n",
    "                    try:\n",
    "                        writer.write(frame_bgr)\n",
    "                        frames_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"视频写出失败：{e}\", flush=True)\n",
    "\n",
    "        # 释放资源与总结\n",
    "        if writer is not None:\n",
    "            try:\n",
    "                writer.release()\n",
    "            except Exception:\n",
    "                pass\n",
    "            print(f\"{v} 输出视频已保存：{out_vid_path}，帧率约 {fps_out:.2f} fps\", flush=True)\n",
    "        print(f\"{v} 完成：消费 {frames_count} 帧\", flush=True)\n",
    "        session[v] = {\"result_dir\": str(result_root), \"frames\": frames_count}\n",
    "\n",
    "    # 打印 UKF 总结（若启用）\n",
    "    if use_ukf:\n",
    "        if ukf_calls_total > 0:\n",
    "            avg_ms = (ukf_time_sum_total / ukf_calls_total) * 1000.0\n",
    "            print(f\"UKF 平均耗时：{avg_ms:.3f} ms（{ukf_calls_total} 次调用；无测量跳过 {ukf_skipped_no_meas} 帧）\", flush=True)\n",
    "        else:\n",
    "            print(f\"UKF 未产生有效调用（可能无检测或过滤导致；无测量跳过 {ukf_skipped_no_meas} 帧）\", flush=True)\n",
    "\n",
    "    return session\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_dir = SRC_DIR\n",
    "    print(\"运行阶段二：从阶段一的产物读取进行渲染与视频写出（硬件UKF可选）\")\n",
    "    res = stage2_consume_hw(\n",
    "        video_dir,\n",
    "        save_video=True,\n",
    "        use_ukf=True,          # 若设备具备 PYNQ 与 bitstream，可改 True\n",
    "        bitstream_path=BITSTREAM_PATH,\n",
    "        ukf_q=0.05,\n",
    "        ukf_r=0.05,\n",
    "    )\n",
    "    print(\"阶段二结果:\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
